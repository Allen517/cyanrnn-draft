\relax 
\citation{kempe2003maximizing}
\citation{goyal2010learning}
\citation{gomez2013modeling}
\citation{WangAAAI15}
\citation{Manavoglu2003userbehaviormodels}
\citation{goldberg2014word2vec}
\citation{mikolov2010recurrent}
\citation{sundermeyer2012lstm}
\citation{DuKDD2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{fig:mot}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  An example of crossing dependency problem in sequence modeling. }}{1}}
\citation{bahdanau2014neural}
\citation{tu2016modeling}
\@writefile{toc}{\contentsline {section}{\numberline {2}Model}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Background}{2}}
\newlabel{eq:cond_prob}{{2.1}{2}}
\newlabel{eq:pooling_frame}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The architecture of CYAN-RNN. The figure presents the case when modeling the generation of the $(k+1)$-th propagation. The sequence at bottom is the observed propagations and the sequence at top is the predictive propagations. The blue rectangles refer to representations of hidden units. The yellow rectangle is a general form of attention function $s_k=\textit  {AttentionFunc}(t_{k-1}, \{h_1,\ldots  ,h_k\})$.}}{3}}
\newlabel{fig:cyrnn_frame}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Attention Mechanism}{3}}
\newlabel{eq:target_embedding}{{2}{3}}
\newlabel{eq:alpha}{{3}{3}}
\newlabel{eq:score}{{4}{3}}
\newlabel{fig:att}{{3(a)}{3}}
\newlabel{sub@fig:att}{{(a)}{3}}
\newlabel{fig:cov}{{3(b)}{3}}
\newlabel{sub@fig:cov}{{(b)}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two kinds of implementation on attention layer. (a) The attention mechanism applied in CYAN-RNN; (b) The attention mechanism with coverage applied in CYAN-RNN (cov). Note that $\textbf  {h}_k=(h_1,\ldots  ,h_k)$ is matrix assembled by all historical propagation embeddings at step $k$, and $\textbf  {V}_k=(V_1,\ldots  ,V_k)$ is a coverage martix containing all coverage vectors at step $k$.}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Coverage}{3}}
\newlabel{sec:coverage}{{2.3}{3}}
\citation{chauvin1995backpropagation}
\citation{chung2014empirical}
\citation{kingma2015method}
\citation{henaff2016orthogonal}
\citation{prechelt1998automatic}
\citation{DuKDD2016}
\citation{goyal2010learning}
\citation{vere1988introduction}
\citation{hawkes1971spectra}
\citation{LeskovecICML07}
\citation{LeskovecWWW08}
\citation{Erdos60}
\newlabel{eq:cov}{{5}{4}}
\newlabel{eq:att_cov}{{6}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Length of Dependence}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Optimization}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{4}}
\newlabel{sec:exp}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Baselines}{4}}
\newlabel{eq:hawke_intens_func}{{8}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Synthetic Data and Results Anlaysis}{4}}
\citation{voorhees1999trec}
\citation{voorhees1999trec}
\newlabel{fig:pred_usr_toy_cp_exp}{{4(a)}{5}}
\newlabel{sub@fig:pred_usr_toy_cp_exp}{{(a)}{5}}
\newlabel{fig:pred_usr_toy_cp_ray}{{4(b)}{5}}
\newlabel{sub@fig:pred_usr_toy_cp_ray}{{(b)}{5}}
\newlabel{fig:pred_usr_toy_rand_exp}{{4(c)}{5}}
\newlabel{sub@fig:pred_usr_toy_rand_exp}{{(c)}{5}}
\newlabel{fig:pred_usr_toy_rand_ray}{{4(d)}{5}}
\newlabel{sub@fig:pred_usr_toy_rand_ray}{{(d)}{5}}
\newlabel{fig:pred_tm_toy_rmse}{{4(e)}{5}}
\newlabel{sub@fig:pred_tm_toy_rmse}{{(e)}{5}}
\newlabel{fig:pred_usr_real}{{4(f)}{5}}
\newlabel{sub@fig:pred_usr_real}{{(f)}{5}}
\newlabel{fig:pred_tm_real_rmse}{{4(g)}{5}}
\newlabel{sub@fig:pred_tm_real_rmse}{{(g)}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparisons on baselines and our proposed models. (a)$\sim $(e) The predictions of next activated user and time on toy data produced from different networks and propagation models; (f) and (g) The predictions of next activated user and time on real data.}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {CP, Exp}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {CP, Rayleign}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Random, Exp}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Random, Rayleign}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(e)}{\ignorespaces {RMSE on toy data}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(f)}{\ignorespaces {Real data}}}{5}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(g)}{\ignorespaces {RMSE on real data}}}{5}}
\newlabel{fig:cyan_deps}{{5(a)}{6}}
\newlabel{sub@fig:cyan_deps}{{(a)}{6}}
\newlabel{fig:cyan_cov_deps}{{5(b)}{6}}
\newlabel{sub@fig:cyan_cov_deps}{{(b)}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Sample alignments on a fragement of cascade. The y-axis is the users who will be activated next sequentiallly from top to bottom. The x-axis is the activated order related to next activated user in the cascade. Each pixel shows the weight $\alpha _{k,i}$ related to $i$-th propagation embedding at each step $k$, in grayscale (0:black, 1:white). (a) the alignments inferred by CYAN-RNN; (b) the alignments inferred by CYAN-RNN(cov). }}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\newlabel{fig:att_cp_infer}{{6(a)}{6}}
\newlabel{sub@fig:att_cp_infer}{{(a)}{6}}
\newlabel{fig:cov_cp_infer}{{6(b)}{6}}
\newlabel{sub@fig:cov_cp_infer}{{(b)}{6}}
\newlabel{fig:att_rand_infer}{{6(c)}{6}}
\newlabel{sub@fig:att_rand_infer}{{(c)}{6}}
\newlabel{fig:cov_rand_infer}{{6(d)}{6}}
\newlabel{sub@fig:cov_rand_infer}{{(d)}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualization of network inference. Edges in grey are the correct inferred edges, while edges highlighted in red are either missed or estimated falsely. (a) and (b) CP network inferred by CYAN-RNN and CYAN-RNN(cov) respectively; (c) and (d) Random network inferred by CYAN-RNN and CYAN-RNN(cov) respectively. }}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{6}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Real Data and Result Analysis}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{6}}
\bibstyle{named}
\bibdata{/home/yqwang/Documents/bibtex/social}
\bibcite{bahdanau2014neural}{\citeauthoryear {Bahdanau \bgroup \em  et al.\egroup }{2014}}
\bibcite{chauvin1995backpropagation}{\citeauthoryear {Chauvin and Rumelhart}{1995}}
\bibcite{chung2014empirical}{\citeauthoryear {Chung \bgroup \em  et al.\egroup }{2014}}
\bibcite{DuKDD2016}{\citeauthoryear {Du \bgroup \em  et al.\egroup }{2016}}
\bibcite{Erdos60}{\citeauthoryear {Erd\H {o}s and R{\'e}nyi}{1960}}
\bibcite{goldberg2014word2vec}{\citeauthoryear {Goldberg and Levy}{2014}}
\bibcite{gomez2013modeling}{\citeauthoryear {Gomez-Rodriguez \bgroup \em  et al.\egroup }{2013}}
\bibcite{goyal2010learning}{\citeauthoryear {Goyal \bgroup \em  et al.\egroup }{2010}}
\bibcite{hawkes1971spectra}{\citeauthoryear {Hawkes}{1971}}
\bibcite{henaff2016orthogonal}{\citeauthoryear {Henaff \bgroup \em  et al.\egroup }{2016}}
\bibcite{kempe2003maximizing}{\citeauthoryear {Kempe \bgroup \em  et al.\egroup }{2003}}
\bibcite{kingma2015method}{\citeauthoryear {Kingma and Adam}{2015}}
\bibcite{LeskovecICML07}{\citeauthoryear {Leskovec and Faloutsos}{2007}}
\bibcite{LeskovecWWW08}{\citeauthoryear {Leskovec \bgroup \em  et al.\egroup }{2008}}
\bibcite{Manavoglu2003userbehaviormodels}{\citeauthoryear {Manavoglu \bgroup \em  et al.\egroup }{2003}}
\bibcite{mikolov2010recurrent}{\citeauthoryear {Mikolov \bgroup \em  et al.\egroup }{2010}}
\bibcite{prechelt1998automatic}{\citeauthoryear {Prechelt}{1998}}
\bibcite{sundermeyer2012lstm}{\citeauthoryear {Sundermeyer \bgroup \em  et al.\egroup }{2012}}
\bibcite{tu2016modeling}{\citeauthoryear {Tu \bgroup \em  et al.\egroup }{2016}}
\bibcite{vere1988introduction}{\citeauthoryear {Vere-Jones}{1988}}
\bibcite{voorhees1999trec}{\citeauthoryear {Voorhees}{1999}}
\bibcite{WangAAAI15}{\citeauthoryear {Wang \bgroup \em  et al.\egroup }{2015}}
